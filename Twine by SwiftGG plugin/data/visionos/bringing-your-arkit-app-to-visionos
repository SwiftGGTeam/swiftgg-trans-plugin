{"Bringing your ARKit app to visionOS": {"zh": "将 ARKit 应用移植到 visionOS", "tips": ""}, "Update an iPadOS or iOS app that uses ARKit, and provide an equivalent experience in visionOS.": {"zh": "更新使用了 ARKit 的 iPadOS 或 iOS 应用，并在 visionOS 中提供相同的体验。", "tips": ""}, "Overview": {"zh": "概述", "tips": ""}, "If you use ARKit to create an augmented reality experience on iPhone or iPad, you need to rethink your use of that technology when bringing your app to visionOS. ARKit plays a crucial role in delivering your content to the display in iPadOS and iOS. In visionOS, you use ARKit only to acquire data about the person’s surroundings, and you do so using a different set of APIs.": {"zh": "如果你使用 ARKit 在 iPhone 或 iPad 上创建增强现实体验，那么在将你的应用移植到 visionOS 时，你需要重新考虑对该技术的使用。在 iPadOS 和 iOS 中，ARKit 在向显示屏交付内容方面发挥着至关重要的作用。而在 visionOS 中，你只能使用 ARKit 来获取有关用户周围环境的数据，而且使用的是一套不同的 API。", "tips": ""}, "In visionOS, you don’t need a special view to display an augmented reality interface. Build windows with your app’s content using SwiftUI or UIKit. When you display those windows, visionOS places them in the person’s surroundings for you. If you want to control the placement of any 2D or 3D content in the person’s surroundings, build your content using SwiftUI and RealityKit.": {"zh": "在 visionOS 中，你不需要一个特殊的视图来显示增强现实界面。你只需使用 SwiftUI 或 UIKit 构建包含应用内容的窗口。当你显示这些窗口时，visionOS 会为你将它们放置在用户的周围环境中。如果你想控制用户的周围环境中任意 2D 或 3D 内容的位置，请使用 SwiftUI 和 RealityKit 构建你的内容。", "tips": ""}, "When migrating your app to visionOS, reuse as much of your app’s existing content as you can. visionOS supports most of the same technologies as iOS, so you can reuse project assets, 3D models, and most custom views. Don’t reuse your app’s ARKit code or any code that relies on technologies visionOS doesn’t support.": {"zh": "在将应用迁移到 visionOS 时，请尽可能多地复用应用的当前内容。visionOS 支持与 iOS 相同的大多数技术，因此你可以重复使用项目素材、3D 模型和大多数自定义视图。但不要复用应用的 ARKit 代码或任何依赖于 visionOS 平台不支持技术的代码。", "tips": ""}, "For general guidance on how to port apps to visionOS, see Bringing your existing apps to visionOS.": {"zh": "有关如何将应用移植到 visionOS 的一般指导，请参阅将现有应用移植到 visionOS。", "tips": ""}, "Adopt technologies available in both iOS and visionOS": {"zh": "采用 iOS 和 visionOS 兼容的技术", "tips": ""}, "To create a single app that runs in both iOS and visionOS, use technologies that are available on both platforms. While ARKit in iOS lets you create your interface using several different technologies, the preferred technologies in visionOS are SwiftUI and RealityKit. If you’re not currently using RealityKit for 3D content, consider switching to it before you start adding visionOS support. If you retain code that uses older technologies in your iOS app, you might need to re-create much of that code using RealityKit when migrating to visionOS.": {"zh": "要创建一个既可在 iOS 又可以在 visionOS 中运行的应用，请使用两个平台上兼容的技术。iOS 中的 ARKit 可让你使用多种不同的技术创建界面，而 visionOS 中的首选技术是 SwiftUI 和 RealityKit。如果你目前没有使用 RealityKit 来制作 3D 内容，请考虑在开始添加 visionOS 支持之前切换到 RealityKit。如果你的 iOS 应用中保留了使用旧技术的代码，那么在迁移到 visionOS 时，你可能需要使用 RealityKit 重新创建其中的大部分代码。", "tips": ""}, "If you use Metal to draw your app’s content, you can bring your code to visionOS to create content for 2D views or to create fully immersive experiences. You can’t use Metal to create 3D content that integrates with the person’s surroundings. This restriction prevents apps from sampling pixels of the person’s surroundings, which might contain sensitive information. For information on how to create a fully immersive experience with Metal, see Drawing fully immersive content using Metal.": {"zh": "如果你使用 Metal 绘制应用的内容，你可以将代码移植到 visionOS，为 2D 视图创建内容或创建完全沉浸式体验。你不能使用 Metal 创建与用户周围环境相融合的 3D 内容。这一限制可防止应用对用户周围环境的像素进行采样，因为这些像素可能包含敏感信息。有关如何使用 Metal 创建完全沉浸式体验的信息，请参阅使用 Metal 绘制完全沉浸式内容。", "tips": ""}, "Convert 3D assets to the USDZ format": {"zh": "将 3D 素材转换为 USDZ 格式", "tips": ""}, "The recommended format for 3D assets in iOS and visionOS is USDZ. This format offers a compact single file for everything, including your models, textures, behaviors, physics, anchoring, and more. If you have assets that don’t use this format, use the Reality Converter tool that comes with Xcode to convert them for your project.": {"zh": "iOS 和 visionOS 中 3D 素材的推荐格式是 USDZ。这种格式为所有内容（包括模型、纹理、行为、物理、锚点等）提供了一个紧凑的单一文件。如果你的素材不使用这种格式，请使用 Xcode 自带的 Reality Converter 工具为你的项目进行转换。", "tips": ""}, "When building 3D scenes for visionOS, use Reality Composer Pro to create your scenes that incorporate your USDZ assets. With Reality Composer Pro, you can import your USD files and edit them in place, nondestructively. If your iOS app applies custom materials to your assets, convert those materials to shader graphs in the app.": {"zh": "在为 visionOS 构建 3D 场景时，请使用 Reality Composer Pro 创建包含 USDZ 素材的场景。使用 Reality Composer Pro，你可以导入你的 USD 文件，并进行无损的原装编辑。如果你的 iOS 应用为你的素材添加了自定义材质，请在应用中将这些材质转换为着色器图形。", "tips": ""}, "Although you can bring models and materials to your project using USDZ files, you can’t bring custom shaders you wrote using Metal. Replace any custom shader code with MaterialX shaders. Many digital content creation tools support the MaterialX standard, and let you create dynamic shaders and save them with your USDZ files. Reality Composer Pro and RealityKit support MaterialX shaders, and incorporate them with your other USDZ asset content. For more information about MaterialX, see https://materialx.org.": {"zh": "虽然你可以使用 USDZ 文件将模型和材质移植到项目，但你无法移植使用了 Metal 编写的自定义着色器。请使用 MaterialX 着色器替换任何自定义着色器代码。许多数字内容创建工具都支持 MaterialX 标准，可让你创建动态着色器并将其与 USDZ 文件一起保存。Reality Composer Pro 和 RealityKit 均支持 MaterialX 着色器，并将它们与其他 USDZ 素材内容结合在一起。有关 MaterialX 的更多信息，请参阅 https://materialx.org。", "tips": ""}, "Update your interface to support visionOS": {"zh": "更新界面以支持 visionOS", "tips": ""}, "In visionOS, you manage your app’s content, and the system handles the integration of that content with the person’s surroundings. This approach differs from iOS, where you use a special ARKit view to blend your content and the live camera content. Bringing your interface to visionOS therefore means you need to remove this special ARKit view and focus only on your content.": {"zh": "在 visionOS 中，你负责管理应用的内容，而系统会负责处理这些内容与用户周围环境的整合。这是与 iOS 不同的一点：在 iOS 中，你使用特殊的 ARKit 视图将你的内容与实时摄像头内容融合在一起。因此，将你的界面移植到 visionOS 意味着你需要移除这个特殊的 ARKit 视图，并只专注于你的内容。", "tips": ""}, "If you can display your app’s content using SwiftUI or UIKit views, build a window with those views and present it from your visionOS app. If you use other technologies to incorporate 2D or 3D content into the person’s surroundings, make the following substitutions in the visionOS version of your app.": {"zh": "如果你可以使用 SwiftUI 或 UIKit 视图来显示应用的内容，那么就用这些视图构建一个窗口，并从你的 visionOS 应用中将其呈现出来。如果你使用其他技术将 2D 或 3D 内容融入用户周围的环境，请在你的应用的 visionOS 版本中进行以下替换。", "tips": ""}, "If you create your AR experience using:": {"zh": "如果你使用了以下框架创建 AR 体验：", "tips": ""}, "Update to:": {"zh": "更新为：", "tips": ""}, "RealityKit and ARView": {"zh": "RealityKit 和 ARView", "tips": ""}, "RealityKit and RealityView": {"zh": "RealityKit 和 RealityView", "tips": ""}, "SceneKit and ARSCNView": {"zh": "SceneKit 和 ARSCNView", "tips": ""}, "SpriteKit and ARSKView": {"zh": "SpriteKit 和 ARSKView", "tips": ""}, "RealityKit or SwiftUI": {"zh": "RealityKit 或 SwiftUI", "tips": ""}, "A RealityView is a SwiftUI view that manages the content and animations you create using RealityKit and Reality Composer Pro. You can add a RealityView to any of your app’s windows to display 2D or 3D content. You can also add the view to an ImmersiveSpace scene, which you use to integrate your RealityKit content into the person’s surroundings.": {"zh": "RealityView 是一种 SwiftUI 视图，用于管理使用 RealityKit 和 Reality Composer Pro 创建的内容和动画。你可以将 RealityView 添加到应用的任何窗口中，以显示 2D 或 3D 内容。你还可以将视图添加到 ImmersiveSpace 场景中，用来将 RealityKit 内容整合到用户的周围环境中。", "tips": ""}, "Note": {"zh": "注意", "tips": ""}, "You can load iOS storyboards into a visionOS app, but you can’t customize your interface for visionOS or include 3D content. If you want to share interface files between iOS and visionOS, adopt SwiftUI views or create your interface programmatically.": {"zh": "你可以将 iOS 故事板加载到 visionOS 应用中，但不能为 visionOS 定制界面或加入 3D 内容。如果你想在 iOS 和 visionOS 之间共享界面文件，请采用 SwiftUI 视图或以编程方式创建界面。", "tips": ""}, "For more information about how to use RealityView and respond to interactions with your content, see Adding 3D content to your app.": {"zh": "有关如何使用 RealityView 以及如何响应与内容交互的更多信息，请参阅在应用中添加 3D 内容。", "tips": ""}, "Replace your ARKit code": {"zh": "替换 ARKit 代码", "tips": ""}, "ARKit provides different APIs for iOS and visionOS, and the way you use ARKit services on the platforms is also different. In iOS, you must use ARKit to put your content onscreen, and you can also use it to manage interactions between your content and a person’s surroundings. In visionOS, the system puts your content onscreen, so you only use ARKit to manage interactions with the surroundings. Because of this more limited usage, some apps don’t need ARKit at all in visionOS.": {"zh": "ARKit 为 iOS 和 visionOS 提供了不同的 API，在这两个平台上使用 ARKit 服务的方式也有所不同。在 iOS 中，你需要使用 ARKit 将内容投至屏幕上，也可以用它来管理内容与用户周围环境之间的交互。而在 visionOS 中，系统会将内容投至屏幕，因此你仅使用 ARKit 管理与周围环境的交互。由于这种使用方式比较有限，有些应用在 visionOS 中完全不需要 ARKit。", "tips": ""}, "The only time you use ARKit in visionOS is when you need one of the following services:": {"zh": "只有在需要以下服务时，你才会在 visionOS 中使用 ARKit：", "tips": ""}, "Plane detection": {"zh": "平面检测", "tips": ""}, "Image tracking": {"zh": "图像追踪", "tips": ""}, "Scene reconstruction": {"zh": "场景重建", "tips": ""}, "Hand tracking": {"zh": "手部追踪", "tips": ""}, "World tracking and device-pose prediction": {"zh": "世界追踪和设备姿态预测", "tips": ""}, "Use plane detection, image tracking, and scene reconstruction to facilitate interactions between your app’s virtual content and real-world items. For example, use plane detection to detect a tabletop on which to place your content. Use world tracking to record anchors that you want to persist between launches of your app. Use hand tracking if your app requires custom hands-based input.": {"zh": "使用平面检测、图像追踪和场景重建来促进应用的虚拟内容与现实世界物品之间的交互。例如，使用平面检测来检测放置内容的桌面。使用世界追踪来记录在应用重启时需要保存的锚点。如果你的应用需要基于手的自定义输入，使用手部追踪。", "tips": ""}, "To start ARKit services in your app, create an ARKitSession object and run it with the data providers for each service. Unlike ARKit in iOS, services in visionOS are independent of one another, and you can start and stop each one at any time. The following example shows how to detect horizontal and vertical planes. Data providers deliver new information using an asynchronous sequence.": {"zh": "要在应用中启动 ARKit 服务，请创建一个 ARKitSession 对象，并与每个服务的数据提供源一起运行。与 iOS 中的 ARKit 不同，visionOS 中的服务彼此独立，你可以随时启动或停止单个服务。下面的示例展示了如何检测水平和垂直平面。数据提供源使用异步序列传递新的信息。", "tips": ""}, "If you use the world-tracking data provider in visionOS, ARKit automatically persists the anchors you add to your app’s content. You don’t need to persist these anchors yourself.": {"zh": "如果你使用了 visionOS 中的世界追踪数据提供源，ARKit 会自动保存你添加到应用内容中的锚点。你无需自己保存这些锚点。", "tips": ""}, "For more information about how to use ARKit, see ARKit.": {"zh": "有关如何使用 ARKit 的更多信息，请参阅 ARKit。", "tips": ""}, "Isolate ARKit features not available in visionOS": {"zh": "隔离在 visionOS 中不可用的 ARKit 功能", "tips": ""}, "If your app uses ARKit features that aren’t present in visionOS, isolate that code to the iOS version of your app. The following features are available in iOS, but don’t have an equivalent in visionOS:": {"zh": "如果你的应用使用了 visionOS 中没有的 ARKit 功能，请将该代码隔离到 iOS 版本的应用中。以下功能在 iOS 中可用，但在 visionOS 中没有相应的功能：", "tips": ""}, "Face tracking": {"zh": "面部追踪", "tips": ""}, "Body tracking": {"zh": "身体追踪", "tips": ""}, "Geotracking and placing anchors using a latitude and longitude": {"zh": "地理追踪和使用经纬度放置锚点", "tips": ""}, "Object detection": {"zh": "物体检测", "tips": ""}, "App Clip Code detection": {"zh": "应用剪辑代码检测", "tips": ""}, "Video frame post-processing": {"zh": "视频帧后处理", "tips": ""}, "Although whole body tracking isn’t available in visionOS, you can track the hands of the person wearing the device. Hand gestures are an important way of interacting with content in visionOS. SwiftUI handles common types of interactions like taps and drags, but you can use custom hand tracking for more complex gestures your app supports.": {"zh": "虽然 visionOS 中不提供全身追踪功能，但可以追踪佩戴设备用户的双手。在 visionOS 中，手势是与内容交互的重要方式。SwiftUI 可处理常见类型的交互，如点击和拖动，但你也可以使用自定义手势追踪来实现应用支持的复杂手势。", "tips": ""}, "If you use ARKit raycasting in iOS to detect interactions with objects in the person’s surroundings, you might not need that code in visionOS. SwiftUI and RealityKit handle both direct and indirect interactions with your app’s content in 3D space, eliminating the need for raycasting in many situations. In other situations, you can use the features of ARKit and RealityKit to manage interactions with your content. For example, you might use ARKit hand tracking to determine where someone is pointing in the scene, and use scene reconstruction to build a mesh you can integrate into your RealityKit content.": {"zh": "如果你在 iOS 中使用 ARKit 射线来检测与用户周围环境中的物体的交互，那么你可能不需要在 visionOS 中使用该代码。SwiftUI 和 RealityKit 可在 3D 空间中处理与应用内容的直接和间接交互，因此在很多情况下都无需进行射线检测。在其他情况下，你可以使用 ARKit 和 RealityKit 的功能来管理与内容的交互。例如，你可以使用 ARKit 的手部追踪功能来确定用户在场景中的指向，然后使用场景重建功能来构建一个网格，并将其集成到 RealityKit 内容中。", "tips": ""}}